{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word2vec을 활용한 모델 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_IN_PATH = './data_in/'\n",
    "TRAIN_CLEAN_DATA = 'train_clean.csv'\n",
    "\n",
    "train_data = pd.read_csv(DATA_IN_PATH + TRAIN_CLEAN_DATA)\n",
    "reviews = list(train_data['review'])\n",
    "sentiments = list(train_data['sentiment'])\n",
    "\n",
    "sentences = []\n",
    "for review in reviews:\n",
    "    sentences.append(review.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 300   # 워드 벡터 특징값 수\n",
    "min_word_count = 40  # 단어에 대한 최소 빈도 수\n",
    "num_workers = 4      # 프로세스 개수\n",
    "context = 10         # 컨텍스트 윈도우 크기 \n",
    "downsampling = 1e-3  # 다운 샘플링 비율"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- num_features: 각 단어에 대해 임베딩된 벡터의 차원을 정한다\n",
    "- min_word_count: 모델에 의미 있는 단어를 가지고 학습하기 위해 적은 빈도 수의 단어들은 학습하지 않는다\n",
    "- num_workers: 모델 학습 시 학습을 위한 프로세스 개수를 지정한다.\n",
    "- context: word2vec을 수행하기 위한 컨텍스트 윈도우 크기를 지정한다.\n",
    "- downsampling: word2vec 학습을 수행할 때 빠른 학습을 위해 정답 단어 라벨에 대한 다운 샘플링 비율을 지정한다. 보통 0.001이 좋은 성능을 낸다고 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\zlslsp54\\anaconda3\\envs\\tensorflow\\lib\\site-packages (3.7.1)\n",
      "Requirement already satisfied: six>=1.5.0 in c:\\users\\zlslsp54\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from gensim) (1.12.0)\n",
      "Requirement already satisfied: smart-open>=1.7.0 in c:\\users\\zlslsp54\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from gensim) (1.8.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in c:\\users\\zlslsp54\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from gensim) (1.15.4)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\zlslsp54\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from gensim) (1.1.0)\n",
      "Requirement already satisfied: boto3 in c:\\users\\zlslsp54\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from smart-open>=1.7.0->gensim) (1.9.123)\n",
      "Requirement already satisfied: boto>=2.32 in c:\\users\\zlslsp54\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from smart-open>=1.7.0->gensim) (2.49.0)\n",
      "Requirement already satisfied: bz2file in c:\\users\\zlslsp54\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from smart-open>=1.7.0->gensim) (0.98)\n",
      "Requirement already satisfied: requests in c:\\users\\zlslsp54\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from smart-open>=1.7.0->gensim) (2.21.0)\n",
      "Requirement already satisfied: botocore<1.13.0,>=1.12.123 in c:\\users\\zlslsp54\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from boto3->smart-open>=1.7.0->gensim) (1.12.123)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in c:\\users\\zlslsp54\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from boto3->smart-open>=1.7.0->gensim) (0.2.0)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in c:\\users\\zlslsp54\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from boto3->smart-open>=1.7.0->gensim) (0.9.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\zlslsp54\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from requests->smart-open>=1.7.0->gensim) (2018.11.29)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\zlslsp54\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from requests->smart-open>=1.7.0->gensim) (2.8)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in c:\\users\\zlslsp54\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from requests->smart-open>=1.7.0->gensim) (1.24.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\zlslsp54\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from requests->smart-open>=1.7.0->gensim) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in c:\\users\\zlslsp54\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from botocore<1.13.0,>=1.12.123->boto3->smart-open>=1.7.0->gensim) (2.7.5)\n",
      "Requirement already satisfied: docutils>=0.10 in c:\\users\\zlslsp54\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from botocore<1.13.0,>=1.12.123->boto3->smart-open>=1.7.0->gensim) (0.14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 19.0.3, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "진행 상황 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-09 16:36:32,534 : INFO : 'pattern' package not found; tag filters are not available for English\n",
      "2019-05-09 16:36:32,547 : INFO : collecting all words and their counts\n",
      "2019-05-09 16:36:32,548 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-09 16:36:32,924 : INFO : PROGRESS: at sentence #10000, processed 1221909 words, keeping 55812 word types\n",
      "2019-05-09 16:36:33,290 : INFO : PROGRESS: at sentence #20000, processed 2429834 words, keeping 74689 word types\n",
      "2019-05-09 16:36:33,471 : INFO : collected 82107 word types from a corpus of 3029622 raw words and 25000 sentences\n",
      "2019-05-09 16:36:33,472 : INFO : Loading a fresh vocabulary\n",
      "2019-05-09 16:36:33,642 : INFO : effective_min_count=40 retains 8132 unique words (9% of original 82107, drops 73975)\n",
      "2019-05-09 16:36:33,643 : INFO : effective_min_count=40 leaves 2648221 word corpus (87% of original 3029622, drops 381401)\n",
      "2019-05-09 16:36:33,682 : INFO : deleting the raw counts dictionary of 82107 items\n",
      "2019-05-09 16:36:33,686 : INFO : sample=0.001 downsamples 29 most-common words\n",
      "2019-05-09 16:36:33,687 : INFO : downsampling leaves estimated 2490621 word corpus (94.0% of prior 2648221)\n",
      "2019-05-09 16:36:33,729 : INFO : estimated required memory for 8132 words and 300 dimensions: 23582800 bytes\n",
      "2019-05-09 16:36:33,730 : INFO : resetting layer weights\n",
      "2019-05-09 16:36:33,912 : INFO : training model with 4 workers on 8132 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2019-05-09 16:36:34,932 : INFO : EPOCH 1 - PROGRESS: at 17.95% examples, 448487 words/s, in_qsize 7, out_qsize 0\n",
      "2019-05-09 16:36:35,937 : INFO : EPOCH 1 - PROGRESS: at 34.90% examples, 434826 words/s, in_qsize 7, out_qsize 0\n",
      "2019-05-09 16:36:36,958 : INFO : EPOCH 1 - PROGRESS: at 53.08% examples, 438603 words/s, in_qsize 8, out_qsize 0\n",
      "2019-05-09 16:36:37,962 : INFO : EPOCH 1 - PROGRESS: at 72.84% examples, 450854 words/s, in_qsize 6, out_qsize 1\n",
      "2019-05-09 16:36:38,982 : INFO : EPOCH 1 - PROGRESS: at 92.32% examples, 454951 words/s, in_qsize 8, out_qsize 1\n",
      "2019-05-09 16:36:39,349 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-09 16:36:39,361 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-09 16:36:39,364 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-09 16:36:39,390 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-09 16:36:39,391 : INFO : EPOCH - 1 : training on 3029622 raw words (2490488 effective words) took 5.5s, 455051 effective words/s\n",
      "2019-05-09 16:36:40,403 : INFO : EPOCH 2 - PROGRESS: at 17.62% examples, 444942 words/s, in_qsize 8, out_qsize 0\n",
      "2019-05-09 16:36:41,440 : INFO : EPOCH 2 - PROGRESS: at 36.17% examples, 446396 words/s, in_qsize 7, out_qsize 0\n",
      "2019-05-09 16:36:42,444 : INFO : EPOCH 2 - PROGRESS: at 54.34% examples, 448871 words/s, in_qsize 8, out_qsize 0\n",
      "2019-05-09 16:36:43,449 : INFO : EPOCH 2 - PROGRESS: at 72.48% examples, 448267 words/s, in_qsize 8, out_qsize 0\n",
      "2019-05-09 16:36:44,487 : INFO : EPOCH 2 - PROGRESS: at 89.96% examples, 441770 words/s, in_qsize 7, out_qsize 0\n",
      "2019-05-09 16:36:45,043 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-09 16:36:45,059 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-09 16:36:45,062 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-09 16:36:45,089 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-09 16:36:45,090 : INFO : EPOCH - 2 : training on 3029622 raw words (2490967 effective words) took 5.7s, 437795 effective words/s\n",
      "2019-05-09 16:36:46,115 : INFO : EPOCH 3 - PROGRESS: at 17.62% examples, 438735 words/s, in_qsize 8, out_qsize 0\n",
      "2019-05-09 16:36:47,123 : INFO : EPOCH 3 - PROGRESS: at 36.74% examples, 457403 words/s, in_qsize 7, out_qsize 0\n",
      "2019-05-09 16:36:48,177 : INFO : EPOCH 3 - PROGRESS: at 54.65% examples, 446011 words/s, in_qsize 7, out_qsize 0\n",
      "2019-05-09 16:36:49,189 : INFO : EPOCH 3 - PROGRESS: at 71.76% examples, 439459 words/s, in_qsize 7, out_qsize 0\n",
      "2019-05-09 16:36:50,199 : INFO : EPOCH 3 - PROGRESS: at 89.65% examples, 438899 words/s, in_qsize 7, out_qsize 0\n",
      "2019-05-09 16:36:50,658 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-09 16:36:50,687 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-09 16:36:50,696 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-09 16:36:50,713 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-09 16:36:50,714 : INFO : EPOCH - 3 : training on 3029622 raw words (2490659 effective words) took 5.6s, 443277 effective words/s\n",
      "2019-05-09 16:36:51,724 : INFO : EPOCH 4 - PROGRESS: at 17.98% examples, 453324 words/s, in_qsize 7, out_qsize 0\n",
      "2019-05-09 16:36:52,744 : INFO : EPOCH 4 - PROGRESS: at 38.47% examples, 478354 words/s, in_qsize 8, out_qsize 0\n",
      "2019-05-09 16:36:53,764 : INFO : EPOCH 4 - PROGRESS: at 57.27% examples, 472951 words/s, in_qsize 7, out_qsize 0\n",
      "2019-05-09 16:36:54,792 : INFO : EPOCH 4 - PROGRESS: at 78.10% examples, 479916 words/s, in_qsize 8, out_qsize 0\n",
      "2019-05-09 16:36:55,802 : INFO : EPOCH 4 - PROGRESS: at 97.63% examples, 479183 words/s, in_qsize 7, out_qsize 0\n",
      "2019-05-09 16:36:55,897 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-09 16:36:55,907 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-09 16:36:55,924 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-09 16:36:55,932 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-09 16:36:55,933 : INFO : EPOCH - 4 : training on 3029622 raw words (2491046 effective words) took 5.2s, 477958 effective words/s\n",
      "2019-05-09 16:36:56,971 : INFO : EPOCH 5 - PROGRESS: at 18.28% examples, 449399 words/s, in_qsize 8, out_qsize 0\n",
      "2019-05-09 16:36:57,980 : INFO : EPOCH 5 - PROGRESS: at 37.12% examples, 458499 words/s, in_qsize 7, out_qsize 0\n",
      "2019-05-09 16:36:58,983 : INFO : EPOCH 5 - PROGRESS: at 55.32% examples, 456994 words/s, in_qsize 7, out_qsize 0\n",
      "2019-05-09 16:37:00,033 : INFO : EPOCH 5 - PROGRESS: at 72.54% examples, 443672 words/s, in_qsize 7, out_qsize 0\n",
      "2019-05-09 16:37:01,046 : INFO : EPOCH 5 - PROGRESS: at 90.60% examples, 443348 words/s, in_qsize 8, out_qsize 0\n",
      "2019-05-09 16:37:01,625 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-09 16:37:01,626 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-09 16:37:01,658 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-09 16:37:01,665 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-09 16:37:01,667 : INFO : EPOCH - 5 : training on 3029622 raw words (2490898 effective words) took 5.7s, 434947 effective words/s\n",
      "2019-05-09 16:37:01,668 : INFO : training on a 15148110 raw words (12454058 effective words) took 27.8s, 448728 effective words/s\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import word2vec\n",
    "print(\"Training model...\")\n",
    "model = word2vec.Word2Vec(sentences,\n",
    "                         workers=num_workers,\n",
    "                         size=num_features,\n",
    "                         min_count = min_word_count,\n",
    "                         window = context,\n",
    "                         sample = downsampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 저장 해놓기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-09 16:41:03,924 : INFO : saving Word2Vec object under 300features_40minwords_10context, separately None\n",
      "2019-05-09 16:41:03,926 : INFO : not storing attribute vectors_norm\n",
      "2019-05-09 16:41:03,929 : INFO : not storing attribute cum_table\n",
      "2019-05-09 16:41:04,246 : INFO : saved 300features_40minwords_10context\n"
     ]
    }
   ],
   "source": [
    "model_name = \"300features_40minwords_10context\"\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stuff',\n",
       " 'going',\n",
       " 'moment',\n",
       " 'mj',\n",
       " 'started',\n",
       " 'listening',\n",
       " 'music',\n",
       " 'watching',\n",
       " 'odd',\n",
       " 'documentary',\n",
       " 'watched',\n",
       " 'wiz',\n",
       " 'watched',\n",
       " 'moonwalker',\n",
       " 'maybe',\n",
       " 'want',\n",
       " 'get',\n",
       " 'certain',\n",
       " 'insight',\n",
       " 'guy',\n",
       " 'thought',\n",
       " 'really',\n",
       " 'cool',\n",
       " 'eighties',\n",
       " 'maybe',\n",
       " 'make',\n",
       " 'mind',\n",
       " 'whether',\n",
       " 'guilty',\n",
       " 'innocent',\n",
       " 'moonwalker',\n",
       " 'part',\n",
       " 'biography',\n",
       " 'part',\n",
       " 'feature',\n",
       " 'film',\n",
       " 'remember',\n",
       " 'going',\n",
       " 'see',\n",
       " 'cinema',\n",
       " 'originally',\n",
       " 'released',\n",
       " 'subtle',\n",
       " 'messages',\n",
       " 'mj',\n",
       " 'feeling',\n",
       " 'towards',\n",
       " 'press',\n",
       " 'also',\n",
       " 'obvious',\n",
       " 'message',\n",
       " 'drugs',\n",
       " 'bad',\n",
       " 'kay',\n",
       " 'visually',\n",
       " 'impressive',\n",
       " 'course',\n",
       " 'michael',\n",
       " 'jackson',\n",
       " 'unless',\n",
       " 'remotely',\n",
       " 'like',\n",
       " 'mj',\n",
       " 'anyway',\n",
       " 'going',\n",
       " 'hate',\n",
       " 'find',\n",
       " 'boring',\n",
       " 'may',\n",
       " 'call',\n",
       " 'mj',\n",
       " 'egotist',\n",
       " 'consenting',\n",
       " 'making',\n",
       " 'movie',\n",
       " 'mj',\n",
       " 'fans',\n",
       " 'would',\n",
       " 'say',\n",
       " 'made',\n",
       " 'fans',\n",
       " 'true',\n",
       " 'really',\n",
       " 'nice',\n",
       " 'actual',\n",
       " 'feature',\n",
       " 'film',\n",
       " 'bit',\n",
       " 'finally',\n",
       " 'starts',\n",
       " 'minutes',\n",
       " 'excluding',\n",
       " 'smooth',\n",
       " 'criminal',\n",
       " 'sequence',\n",
       " 'joe',\n",
       " 'pesci',\n",
       " 'convincing',\n",
       " 'psychopathic',\n",
       " 'powerful',\n",
       " 'drug',\n",
       " 'lord',\n",
       " 'wants',\n",
       " 'mj',\n",
       " 'dead',\n",
       " 'bad',\n",
       " 'beyond',\n",
       " 'mj',\n",
       " 'overheard',\n",
       " 'plans',\n",
       " 'nah',\n",
       " 'joe',\n",
       " 'pesci',\n",
       " 'character',\n",
       " 'ranted',\n",
       " 'wanted',\n",
       " 'people',\n",
       " 'know',\n",
       " 'supplying',\n",
       " 'drugs',\n",
       " 'etc',\n",
       " 'dunno',\n",
       " 'maybe',\n",
       " 'hates',\n",
       " 'mj',\n",
       " 'music',\n",
       " 'lots',\n",
       " 'cool',\n",
       " 'things',\n",
       " 'like',\n",
       " 'mj',\n",
       " 'turning',\n",
       " 'car',\n",
       " 'robot',\n",
       " 'whole',\n",
       " 'speed',\n",
       " 'demon',\n",
       " 'sequence',\n",
       " 'also',\n",
       " 'director',\n",
       " 'must',\n",
       " 'patience',\n",
       " 'saint',\n",
       " 'came',\n",
       " 'filming',\n",
       " 'kiddy',\n",
       " 'bad',\n",
       " 'sequence',\n",
       " 'usually',\n",
       " 'directors',\n",
       " 'hate',\n",
       " 'working',\n",
       " 'one',\n",
       " 'kid',\n",
       " 'let',\n",
       " 'alone',\n",
       " 'whole',\n",
       " 'bunch',\n",
       " 'performing',\n",
       " 'complex',\n",
       " 'dance',\n",
       " 'scene',\n",
       " 'bottom',\n",
       " 'line',\n",
       " 'movie',\n",
       " 'people',\n",
       " 'like',\n",
       " 'mj',\n",
       " 'one',\n",
       " 'level',\n",
       " 'another',\n",
       " 'think',\n",
       " 'people',\n",
       " 'stay',\n",
       " 'away',\n",
       " 'try',\n",
       " 'give',\n",
       " 'wholesome',\n",
       " 'message',\n",
       " 'ironically',\n",
       " 'mj',\n",
       " 'bestest',\n",
       " 'buddy',\n",
       " 'movie',\n",
       " 'girl',\n",
       " 'michael',\n",
       " 'jackson',\n",
       " 'truly',\n",
       " 'one',\n",
       " 'talented',\n",
       " 'people',\n",
       " 'ever',\n",
       " 'grace',\n",
       " 'planet',\n",
       " 'guilty',\n",
       " 'well',\n",
       " 'attention',\n",
       " 'gave',\n",
       " 'subject',\n",
       " 'hmmm',\n",
       " 'well',\n",
       " 'know',\n",
       " 'people',\n",
       " 'different',\n",
       " 'behind',\n",
       " 'closed',\n",
       " 'doors',\n",
       " 'know',\n",
       " 'fact',\n",
       " 'either',\n",
       " 'extremely',\n",
       " 'nice',\n",
       " 'stupid',\n",
       " 'guy',\n",
       " 'one',\n",
       " 'sickest',\n",
       " 'liars',\n",
       " 'hope',\n",
       " 'latter']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_features(word, model, num_features):\n",
    "    # 출력 벡터 초기화\n",
    "    feature_vector = np.zeros((num_features), dtype = np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
